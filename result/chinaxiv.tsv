model	params	eval#2023	eval#2024	lora#2024
Aquila2-7B	7295537152	28.848250250008622	30.052131719941165	-2
Atom-7B	7028740096	10.848750286940975	11.121901083648773	9.65354919272987
Baichuan2-7B-Base	7523864576	9.63393202466076	9.881991156344021	9.172034306143868
bloom-3b	3002557440	15.172648146167607	15.07576537427542	-2
bloom-560m	559214592	28.044169952447604	28.24155076451298	-2
bloom-7b1	7084744704	13.136293489049468	12.950307802902802	11.750805428585885
bloomz-3b	3002557440	19.187214328320763	19.059107123739583	-2
bloomz-560m	559214592	38.77742876801622	37.6572408990562	-2
bloomz-7b1	7069016064	15.386272028160016	15.14769026406874	-2
BlueLM-7B-Base	7316254720	4422.868063425761	32602.12531998162	9.508107099092177
CodeLlama-7b-hf	6738546688	6.236449789904188	5.090561402655597	-2
DeciLM-7B	7064135680	9.109229408563957	9.25354810772309	5.421669636802661
deepseek-coder-6.7b-base	6740512768	10.138931791021738	8.666568673211335	-2
deepseek-llm-7b-base	6929104896	10.2272925876428	9.053342802071326	8.246095210030955
falcon-7b	6938039168	15.963135459771266	15.009276906724915	5.251349309787127
gemma-2b	2506172416	22.858052342077013	21.6603844575985	-2
gemma-7b	8537680896	64448107.68257634	3452661.8034154037	-2
gpt-neo-1B3	1322653696	5.645106509506594	4.9232381967175085	4.074434115539411
gpt-neo-2.7B	2663104000	5.1318652943301215	4.469000784377942	3.7170850152819788
internlm2-1_8b	1897731072	13.719357512463102	13.927636889811502	11.61147626530547
internlm2-7b	7737708544	15.533875528456425	13.586980585074903	-2
internlm2-base-7b	7757356032	14.935174552802737	13.799628298037801	8.99170006741812
internlm2-chat-1_8b	1889110016	14.724078094808743	14.792914292093707	-2
internlm2-chat-1_8b-sft	1889110016	15.049797074396386	15.037218687358969	-2
internlm2-chat-7b	7737708544	12.991735333482733	12.570805190859122	-2
internlm2-chat-7b-sft	7737708544	13.123580850508953	12.652546334418444	-2
LiteLlama-460M-1T	465863680	8.093006701117298	7.877329291518553	5.22046241529349
Llama-2-7b-ms	6758404096	5.65824697972158	4.86942734189717	3.941072161029811
miniCPM-bf16	2738520576	16.34689251293726	14.97824772751796	12.244138360876407
Mistral-7B-v0.1	7262703616	6.6211300700708104	5.951055630321369	4.954598656774467
Mistral-7B-v0.2-hf	7262703616	6.639456891046497	6.09937273168469	5.0087016469332095
nlp_polylm_qwen_7b_text_generation	7721324544	10.409963994920316	9.785966348986838	-2
open_llama_7b_v2	6758404096	7.188848177363413	6.8394687539930485	5.625202200003087
opt-125	126566400	16.989760610580937	14.589483354915235	7.2521551377577715
opt-1b3	1322835968	9.679114472813763	8.719473128068874	5.026911690931931
phi-2	2790169600	6.029122838403478	5.085428893031818	3.8106563949978702
pythia-1b	1016394752	9.468148611884759	8.680959788265225	6.781975115121671
pythia-6.9b-deduped	6874515456	7.428262178050418	6.775185713604736	5.338255862160543
Qwen1.5-0.5B	463987712	17.16792966327078	16.73722129515114	-2
Qwen1.5-1.8B	1836828672	13.735997103415153	13.414812291532423	-2
Qwen1.5-4B	3950369280	10.845515003366277	10.984530351221496	-2
Qwen1.5-7B	7741313024	9.690842282521734	9.65016875566852	8.874974009725968
RedPajama-INCITE-7B-Base	6874515456	7.629295704159116	7.155576986254818	5.53065518497458
SOLAR-10.7B-v1.0	10731524096	7.291902968864628	6.948421219115005	-2
stablelm-2-1_6b	1652084736	8.696676828930922	7.797068988568973	6.426663533578732
stablelm-3b-4e1t	2795443200	6.662487003924278	5.927789651220919	-2
TinyLlama-1.1B-intermediate-step-1431k-3T	1106356224	5.714550531141072	6.088250953981341	4.8185798515796
TinyLlama-1.1B-intermediate-step-240k-503b	1100048384	8.576144317216176	7.758241097049986	-2
xgen-7b-4k-base	6915690496	4.00860759093679	3.4001104994979667	2.998444781530413
XVERSE-7B	7319834624	4.831159947664657	4.586710407064002	4.318016750202448
Yi-6B	6079188992	10.123764858855708	9.316750486208274	8.658336429370458
Yi-9B	8829407232	9.16613407636123	8.575207890182849	-2
