# YueDanPing
reliable evalution for LLM foundation models monthly.
It is not wide or deep, but faithfull. 

## evaluation methord
train on older corpus, evaluate on similar fresh corpus.

## result
* perplexity: lower is better

### result on wikinews-20240304
#### corpus  
news-202401/202402 from  wikinews-20240304
| language | 2023 | 2024-01 | 2024-02 |
|----------|------|---------|---------|
| Total    | 1670 | 120     | 74      |
| ar       | 20   | 33      | 4       |
| ca       | 26   | 1       | 0       |
| cs       | 307  | 31      | 16      |
| de       | 37   | 16      | 11      |
| el       | 1    | 0       | 0       |
| en       | 150  | 3       | 27      |
| eo       | 50   | 2       | 1       |
| es       | 77   | 21      | 4       |
| fa       | 7    | 0       | 0       |
| fi       | 1    | 0       | 1       |
| fr       | 315  | 12      | 10      |
| guw      | 679  | 1       | 0       |

#### result
| **model**                                  | **params**      | **eval#2024-01** | **eval#2024-02** | **lora#2024-01** | **lora#2024-02** |
|--------------------------------------------|-----------------|------------------|------------------|------------------|------------------|
| Aquila2-7B                                 | 7,315,525,632   | 16.30403         | 20.89646         | 6.065212         | 7.97123          |
| Atom-7B                                    | 7,028,740,096   | 5.575283         | 7.550279         | 4.573611         | 6.4228           |
| Baichuan2-7B-Base                          | 7,523,864,576   | 4.359303         | 5.794551         | 3.755924         | 5.202254         |
| bloom-3b                                   | 3,012,387,840   | 22.90577         | 31.64106         | 15.83741         | 23.881           |
| bloom-560m                                 | 562,360,320     | 53.86382         | 80.3743          | 35.75742         | 58.1996          |
| bloom-7b1                                  | 7,084,744,704   | 18.33257         | 24.13478         | 12.78142         | 18.5073          |
| bloomz-3b                                  | 3,012,387,840   | 35.71364         | 52.68064         | 17.99012         | 27.33712         |
| bloomz-560m                                | 562,360,320     | 82.51425         | 123.9445         | 41.25399         | 67.0926          |
| bloomz-7b1                                 | 7,084,744,704   | 24.69381         | 35.01303         | 13.94318         | 20.42104         |
| BlueLM-7B-Base                             | 7,316,254,720   | 3411.778         | 427.2565         | 5.219351         | 6.107629         |
| chatglm3-6b-base                           | 6,258,407,424   | 8.133553         | 11.02375         | 4.082908         | 5.597171         |
| CodeLlama-7b-hf                            | 6,758,535,168   | 5.265539         | 7.133512         | 4.422488         | 6.193972         |
| DeciLM-7B                                  | 7,064,135,680   | 7.241643         | 9.448154         | 4.339353         | 5.838205         |
| deepseek-coder-6.7b-base                   | 6,760,501,248   | 4.835029         | 7.916848         | 4.023368         | 6.695955         |
| deepseek-llm-7b-base                       | 6,929,104,896   | 4.610202         | 6.132427         | 3.960884         | 5.419725         |
| falcon-7b                                  | 6,938,039,168   | 15.09715         | 23.14824         | 6.82834          | 10.75367         |
| gemma-2b                                   | 2,515,978,240   | 23.33773         | 23.34022         | 8.73191          | 10.06568         |
| gemma-7b                                   | 8,562,682,880   | 503563.5         | 1415642          | 7.880434         | 9.012646         |
| gpt-neo-1B3                                | 1,322,653,696   | 6.717628         | 10.6243          | 5.811638         | 9.488335         |
| gpt-neo-2.7B                               | 2,663,104,000   | 5.984828         | 9.206106         | 5.09842          | 8.070748         |
| internlm-7b                                | 7,341,936,640   | 15.07735         | 12.5624          | 11.58088         | 10.66008         |
| internlm2-1_8b                             | 1,897,731,072   | 8.192929         | 13.84612         | 6.106452         | 10.48959         |
| internlm2-7b                               | 7,757,356,032   | 5.520153         | 8.289825         | 4.187122         | 6.437863         |
| internlm2-base-7b                          | 7,757,356,032   | 5.231546         | 7.953677         | 3.979664         | 6.262898         |
| internlm2-chat-1_8b                        | 1,897,731,072   | 8.374632         | 14.45481         | 6.21047          | 10.88569         |
| internlm2-chat-1_8b-sft                    | 1,897,731,072   | 8.588778         | 14.94404         | 6.216262         | 10.90602         |
| internlm2-chat-7b                          | 7,757,356,032   | 5.429047         | 7.890384         | 4.251997         | 6.723232         |
| internlm2-chat-7b-sft                      | 7,757,356,032   | 5.541009         | 8.056338         | 4.267017         | 6.705608         |
| LiteLlama-460M-1T                          | 465,863,680     | 9.086187         | 14.09878         | 7.409269         | 11.82525         |
| Llama-2-7b-hf                              | 6,758,404,096   | 4.675434         | 6.207275         | 3.931474         | 5.357683         |
| Llama-2-7b-ms                              | 6,758,404,096   | 4.675434         | 6.207275         | 3.931631         | 5.360066         |
| llama-7b                                   | 6,758,404,096   | 4.96496          | 6.767419         | 4.148877         | 5.791437         |
| miniCPM-bf16                               | 2,738,520,576   | 8.32307          | 11.67591         | 6.262321         | 9.155216         |
| Mistral-7B-v0.1                            | 7,262,703,616   | 4.250147         | 5.588682         | 3.623107         | 4.903256         |
| mpt-7b                                     | 6,649,286,656   | 7.35285          | 9.474119         | -1               | -1               |
| nlp_polylm_qwen_7b_text_generation         | 7,739,215,872   | 6.547418         | 7.270501         | 5.377188         | 6.328094         |
| OLMo-7B                                    | 6,888,095,744   | 7.329988         | 9.873527         | -1               | -1               |
| open_llama_7b                              | 6,758,404,096   | 3.274803         | 5.478099         | 2.874587         | 4.789103         |
| open_llama_7b_v2                           | 6,758,404,096   | 4.884668         | 6.051518         | 4.108351         | 5.270462         |
| opt-125                                    | 126,566,400     | 14.23733         | 24.8076          | 11.9095          | 21.40656         |
| opt-1b3                                    | 1,322,835,968   | 7.649281         | 11.14465         | 6.33929          | 9.609758         |
| phi-2                                      | 2,790,169,600   | 9.475558         | 16.74762         | 7.661525         | 13.45879         |
| pythia-1b                                  | 1,016,394,752   | 9.91897          | 13.5123          | 8.083432         | 11.70023         |
| pythia-6.9b-deduped                        | 6,874,515,456   | 7.26527          | 9.79727          | 5.738915         | 8.085229         |
| Qwen-1_8B-Llamafied                        | 1,844,373,504   | 28.92216         | 19.72609         | 11.91706         | 12.74216         |
| Qwen-7B                                    | 7,739,215,872   | 8.753631         | 7.797002         | 6.987481         | 6.807241         |
| Qwen1.5-0.5B                               | 467,772,416     | 21.22331         | 20.7434          | 15.96482         | 17.05816         |
| Qwen1.5-1.8B                               | 1,844,324,352   | 14.68596         | 14.3309          | 11.14278         | 11.76543         |
| Qwen1.5-4B                                 | 3,966,016,000   | 10.88744         | 10.18894         | 8.417567         | 8.67093          |
| Qwen1.5-7B                                 | 7,741,313,024   | 8.196657         | 8.256778         | 6.501196         | 7.086949         |
| RedPajama-INCITE-7B-Base                   | 6,874,515,456   | 5.997423         | 7.708963         | 5.021287         | 6.759973         |
| SOLAR-10.7B-v1.0                           | 10,762,981,376  | 4.199552         | 5.488511         | 3.459426         | 4.673364         |
| stablelm-2-1_6b                            | 1,652,084,736   | 6.560932         | 8.018926         | 5.511056         | 7.038959         |
| stablelm-3b-4e1t                           | 2,807,960,576   | 5.56371          | 6.910879         | 4.729144         | 6.127542         |
| TinyLlama-1.1B-intermediate-step-240k-503b | 1,106,356,224   | 8.920971         | 13.49263         | 7.127494         | 10.63824         |
| xgen-7b-4k-base                            | 6,915,690,496   | 4.194388         | 6.011444         | 3.612002         | 5.30681          |
| XVERSE-7B                                  | 7,319,834,624   | 3.194532         | 3.67341          | 2.782692         | 3.337815         |
| Yi-6B                                      | 6,079,188,992   | 4.457659         | 6.661217         | 3.735765         | 5.724027         |
| Yi-9B                                      | 8,856,637,440   | 4.042195         | 6.075996         | 3.429222         | 5.222183         |
| Yuan2-2B-hf                                | 2,097,768,448   | 67.75841         | 130.9332         | 17.67953         | 35.89121         |

### result on wikinews-20240122
#### corpus 
news-202401 from  wikinews-20240122
#### result
| Foundation Models                          | just eval | train only lora | train with byt5 tokenizer |   |
|--------------------------------------------|-----------|-----------------|---------------------------|---|
| deepseek-llm-7b-base                       | 4.418595  | 2.775576        | 2.435999                  |   |
| Llama-2-7b-hf                              | 4.496019  | 2.775896        | 2.756618                  |   |
| Yi-6B                                      | 5.031991  | 2.996905        | 2.367179                  |   |
| CodeLlama-7b-hf                            | 5.087177  | 3.045621        | 2.888906                  |   |
| deepseek-coder-6.7b-base                   | 5.15121   | 3.079392        | 2.519493                  |   |
| llama-7b                                   | 5.287015  | 3.155645        | 2.37461                   |   |
| TinyLlama-1.1B-intermediate-step-240k-503b | 8.20445   | 4.419586        | 2.628365                  |   |

